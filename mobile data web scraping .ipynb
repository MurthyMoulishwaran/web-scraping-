{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26d871-ed9f-4986-8cb0-64a3e224daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Avast/131.0.0.0\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.amazon.com/\"\n",
    "}\n",
    "\n",
    "# Function to fetch product title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"span\", attrs={\"id\": \"productTitle\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        title = \"N/A\"\n",
    "    return title\n",
    "\n",
    "# Function to fetch product price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\n",
    "            \"span\", attrs={\"class\": \"a-price aok-align-center reinventPricePriceToPayMargin priceToPay\"}\n",
    "        ).find(\"span\", attrs={\"class\": \"a-price-whole\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        price = \"N/A\"\n",
    "    return price\n",
    "\n",
    "# Function to fetch product rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(\"span\", attrs={\"class\": \"a-icon-alt\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        rating = \"N/A\"\n",
    "    return rating\n",
    "\n",
    "# Function to fetch product availability\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"span\", attrs={\"class\": \"a-size-medium a-color-success\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\n",
    "    return available\n",
    "\n",
    "# Function to fetch product ID (ASIN)\n",
    "def get_product_id(soup):\n",
    "    try:\n",
    "        product_id = soup.find(\"th\", string=lambda x: x and \"ASIN\" in x).find_next_sibling(\"td\").text.strip()\n",
    "    except AttributeError:\n",
    "        product_id = \"N/A\"\n",
    "    return product_id\n",
    "\n",
    "# Function to fetch released year\n",
    "def get_released_year(soup):\n",
    "    try:\n",
    "        released_year = soup.find(\"th\", string=lambda x: x and \"Date First Available\" in x).find_next_sibling(\"td\").text.strip()\n",
    "    except AttributeError:\n",
    "        released_year = \"N/A\"\n",
    "    return released_year\n",
    "\n",
    "# Function to fetch special features\n",
    "def get_special_features(soup):\n",
    "    try:\n",
    "        special_features = soup.find(\n",
    "            \"th\", string=lambda x: x and \"Special Features\" in x\n",
    "        ).find_next_sibling(\"td\").text.strip()\n",
    "    except AttributeError:\n",
    "        special_features = \"N/A\"\n",
    "    return special_features\n",
    "\n",
    "# Function to scrape a single page (using the specific URL with page number)\n",
    "def scrape_page(url, headers, data):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find product links (if any)\n",
    "        links = soup.find_all(\"a\", attrs={\"class\": \"a-link-normal s-no-outline\"})\n",
    "        links_list = [\"https://www.amazon.in\" + link.get(\"href\") for link in links]\n",
    "\n",
    "        # Loop through product links and fetch details\n",
    "        for link in links_list:\n",
    "            try:\n",
    "                product_page = requests.get(link, headers=headers)\n",
    "                product_soup = BeautifulSoup(product_page.content, \"html.parser\")\n",
    "                \n",
    "                # Extract product details\n",
    "                data[\"Title\"].append(get_title(product_soup))\n",
    "                data[\"Price\"].append(get_price(product_soup))\n",
    "                data[\"Rating\"].append(get_rating(product_soup))\n",
    "                data[\"Availability\"].append(get_availability(product_soup))\n",
    "                data[\"Product_ID\"].append(get_product_id(product_soup))\n",
    "                data[\"Released_Year\"].append(get_released_year(product_soup))\n",
    "                data[\"Special_Features\"].append(get_special_features(product_soup))\n",
    "                \n",
    "                # Optional: Sleep to prevent rapid requests\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching details for {link}: {e}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch page: {url}, Status code: {response.status_code}\")\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Base URL for the first page (keeping other query parameters intact)\n",
    "    base_url = \"https://www.amazon.in/s?k=Original+samsung+headphones+only+wired+and+wireless&i=electronics&crid=1LT4VD15B1ANP&qid=1737550580&sprefix=original+samsung+headphones+only+wired+and+wireless%2Celectronics%2C236&ref=sr_pg_{}&page={}&xpid=eVYBOpAtBAROW\"\n",
    "    \n",
    "    data = {\n",
    "        \"Title\": [], \n",
    "        \"Price\": [], \n",
    "        \"Rating\": [], \n",
    "        \"Availability\": [], \n",
    "        \"Product_ID\": [], \n",
    "        \"Released_Year\": [], \n",
    "        \"Special_Features\": []\n",
    "    }\n",
    "    \n",
    "    # Scrape 20 pages\n",
    "    for page in range(1, 21):\n",
    "        print(f\"Scraping page {page}...\")\n",
    "        url = base_url.format(page, page)\n",
    "        scrape_page(url, headers, data)\n",
    "\n",
    "    # Save data to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"amazon_data_with_special_features.csv\", index=False)\n",
    "    print(\"Data saved to amazon_data_with_special_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
